{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f7e4788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlite3 as db\n",
    "from sqlite3 import Error\n",
    "from datetime import datetime\n",
    "\n",
    "%run C:\\Users\\Joshua\\Jupyter_Notebook_Folders\\APIkeys.py\n",
    "%run C:\\Users\\Joshua\\Jupyter_Notebook_Folders\\MacroData2\\db_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf44a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'MacroData2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d088d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BLS_data(seriesIDs, startyear, endyear):\n",
    "    \"\"\"\n",
    "    get data from BLS\n",
    "    \"\"\"\n",
    "    base_url = 'https://api.bls.gov/publicAPI/v2/timeseries/data/'  #this will not change\n",
    "    headers = {'Content-type': 'application/json'}  #This will not changed !\n",
    "\n",
    "    # For the key seriesid enter a list of series names you wish to download\n",
    "    # For the key startyear enter the start year inside \"\"\n",
    "    # For the key endyear enter the end year inside \"\"\n",
    "    \n",
    "    parameters = { \n",
    "        \"seriesid\":seriesIDs,\n",
    "        \"startyear\":str(startyear), \n",
    "        \"endyear\":str(endyear),\n",
    "        \"catalog\":True, \n",
    "        \"calculations\":False, \n",
    "        \"annualaverage\":False,\n",
    "        \"aspects\":False,\n",
    "        \"registrationkey\":os.environ['BLS_API_key'] \n",
    "     }\n",
    "\n",
    "    data = json.dumps(parameters) # Converts the Python dictionary to JSON\n",
    "\n",
    "    p = requests.post(base_url, data=data, headers=headers)\n",
    "    json_data = json.loads(p.text)\n",
    "    \n",
    "    message = \"\"\n",
    "    if json_data['message']:\n",
    "        #message = \"For series \" + seriesIDs + \", no data for years: \"\n",
    "        for i in range(len(json_data['message'])):\n",
    "            message += json_data['message'][i][-4:] + \", \"\n",
    "    \n",
    "    return message, json_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22e1487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_year_increments(startyear, endyear):\n",
    "    \"\"\"\n",
    "    Create start and endyear increments of 20 years or \n",
    "    \"\"\"\n",
    "    if endyear - startyear < 20:\n",
    "        return startyear, endyear\n",
    "    else:\n",
    "        i = startyear\n",
    "        increments = []\n",
    "        while i <= endyear: \n",
    "            start_end_array = []\n",
    "            start_end_array.append(i)\n",
    "            if i + 19 > endyear:\n",
    "                start_end_array.append(endyear)\n",
    "            else:\n",
    "                start_end_array.append(i + 19)\n",
    "            increments.append(start_end_array)\n",
    "            i += 20\n",
    "    \n",
    "    return increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88c6a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframes(json_data):\n",
    "    for i in range(len(json_data['Results']['series'])):\n",
    "        df_dict = pd.DataFrame()\n",
    "        df_dict['series_title'] = json_data['Results']['series'][i]['catalog']['series_title'],\n",
    "        df_dict['series_id'] = json_data['Results']['series'][i]['catalog']['series_id'],\n",
    "        df_dict['seasonality'] = json_data['Results']['series'][i]['catalog']['seasonality'],\n",
    "        df_dict['survey_long_name'] = json_data['Results']['series'][i]['catalog']['survey_name'],\n",
    "        df_dict['survey_short_name'] = json_data['Results']['series'][i]['catalog']['survey_name'][-6:-1],\n",
    "        df_dict['survey_abbreviation'] = json_data['Results']['series'][i]['catalog']['survey_abbreviation'],\n",
    "        df_dict['measure_data_type'] = json_data['Results']['series'][i]['catalog']['measure_data_type'],\n",
    "        df_dict['area'] = json_data['Results']['series'][i]['catalog']['area'],\n",
    "        df_dict['item'] = json_data['Results']['series'][i]['catalog']['item']\n",
    "        df_dict = df_dict.set_index(df_dict['series_id'])\n",
    "        df_dict = df_dict.drop(columns=['series_id'])\n",
    "\n",
    "        df = pd.DataFrame(json_data['Results']['series'][i]['data'])\n",
    "        df['series'] = json_data['Results']['series'][i]['catalog']['series_id']\n",
    "        df['month'] = df['period'].str.replace('M', '')\n",
    "        df['date'] = df['year'] + df['month']\n",
    "        df = df.sort_values(by=['date'], ignore_index=True)\n",
    "        df['date'] = pd.to_numeric(df['date'])\n",
    "        df = df.set_index(df[\"date\"])\n",
    "        df['latest'].iloc[-1] = df['latest'].iloc[-1].upper()\n",
    "        df = df.drop(columns=['year', 'period', 'periodName', 'footnotes', 'month', 'date'])\n",
    "\n",
    "        series_id = json_data['Results']['series'][i]['catalog']['series_id']\n",
    "        create_data_table(series_id, db_name)\n",
    "        add_data_to_db(df, series_id, db_name)\n",
    "\n",
    "        series_dict = series_id + \"_dict\"\n",
    "        create_dict_table(series_dict, db_name)\n",
    "        add_data_to_db(df_dict, series_dict, db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42992dfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_dataframes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m year_increments:\n\u001b[0;32m      4\u001b[0m     message, json_data \u001b[38;5;241m=\u001b[39m get_BLS_data(seriesIDs, j[\u001b[38;5;241m0\u001b[39m], j[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mcreate_dataframes\u001b[49m(json_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_dataframes' is not defined"
     ]
    }
   ],
   "source": [
    "seriesIDs = [\"CUUR0000SA0\", \"CUSR0000SA0\"] \n",
    "year_increments = create_year_increments(1913, 2003)\n",
    "for j in year_increments:\n",
    "    message, json_data = get_BLS_data(seriesIDs, j[0], j[1])\n",
    "    create_dataframes(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1096f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of series\n",
    "number_of_series = len(json_data['Results']['series'])\n",
    "number_of_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7244e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = table_to_df('CUSR0000SA0', db_name)\n",
    "check_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef2d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = table_to_df('CUSR0000SA0_dict', db_name)\n",
    "check_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd685213",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_connection(db_name)\n",
    "c = conn.cursor()\n",
    "    conn_execute(db_name, sql_code1) \n",
    "    \n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6e0194",
   "metadata": {},
   "source": [
    "## Validate Data to Put into Correct Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4739fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "    \n",
    "def create_insert_trigger(tbl_name, db_name):\n",
    "    '''\n",
    "    Enter data into the log table when enter data into the database where the value does not exist or does not\n",
    "    match the value that already exists\n",
    "    '''\n",
    "    conn = create_connection(db_name)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    sql_code = \"\"\"CREATE TRIGGER log_value_after_insert \n",
    "                    AFTER INSERT ON \"\"\" + seriesID + \"\"\" \n",
    "                    BEGIN INSERT INTO value_logs(      \n",
    "                        seriesID,\n",
    "                        year, \n",
    "                        period, \n",
    "                        periodName, \n",
    "                        value, \n",
    "                        date, \n",
    "                        date_action,\n",
    "                        action)\n",
    "                    VALUES(\n",
    "                        new.seriesID,\n",
    "                        new.year,\n",
    "                        new.period,\n",
    "                        new.periodName,\n",
    "                        new.value,\n",
    "                        new.date,\n",
    "                        datetime('now','localtime'),\n",
    "                        'INSERT'    \n",
    "                    );\n",
    "                    END;\"\"\".format(seriesID)\n",
    "    \n",
    "    conn_execute((sql_code)\n",
    "    \n",
    "    conn.close()    \n",
    "\n",
    "def create_update_trigger(tbl_name, db_name):\n",
    "    '''\n",
    "    Enter data into the log table when enter data into the database where the value does not exist or does not\n",
    "    match the value that already exists\n",
    "    '''\n",
    "    conn = create_connection(db_name)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    sql_code = \"\"\"CREATE TRIGGER log_value_after_update \n",
    "                    AFTER UPDATE ON \"\"\" + seriesID + \"\"\"\n",
    "                    WHEN old.value <> new.value\n",
    "                    BEGIN INSERT INTO value_logs(      \n",
    "                        seriesID,\n",
    "                        year, \n",
    "                        period, \n",
    "                        periodName, \n",
    "                        value, \n",
    "                        date, \n",
    "                        date_action,\n",
    "                        action)\n",
    "                    VALUES(\n",
    "                        new.seriesID,\n",
    "                        new.year,\n",
    "                        new.period,\n",
    "                        new.periodName,\n",
    "                        new.value,\n",
    "                        new.date,\n",
    "                        datetime('now','localtime'),\n",
    "                        'INSERT'    \n",
    "                    );\n",
    "                    END;\"\"\".format(seriesID)\n",
    "    conn_execute((sql_code)\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "'''def unique_index(tbl_name, db_name)\n",
    "    \"\"\"\n",
    "    Create a unique index for the date value of the table\n",
    "    \"\"\"\n",
    "    conn = create_connection(db_name)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    sql_code = 'CREATE UNIQUE INDEX idx_date ON ' + tbl_name + '(date)';\n",
    "    \n",
    "    conn_execute(sql_code)'''\n",
    "    \n",
    "def validate_df(df, tbl_name, db_name):\n",
    "    \"\"\"\n",
    "    check if the data from the api df already exists in the table and \n",
    "    if the data in the table is duplicate or inconsistent\n",
    "    return dataframe df without duplicate data or inconsistent data\n",
    "    return dataframe df_dup_data with duplicate date\n",
    "    return dataframe df_inconsistent_data with inconsistent data\n",
    "    \"\"\"\n",
    "    conn = create_connection(db_name)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Set up empty dataframes to use to store data temporarily\n",
    "    df_not_dup_data = pd.DataFrame(columns = list(df.columns))\n",
    "    df_dup_data = pd.DataFrame(columns = list(df.columns))\n",
    "    df_inconsistent_data = pd.DataFrame(columns = list(df.columns))\n",
    "    \n",
    "    if check_table_exists(seriesID, db_name) != 0:\n",
    "        # Check if data already exists in DB\n",
    "        for i, row in df.iterrows():\n",
    "            c.execute(\"SELECT date, value FROM \" + tbl_name + \" WHERE date = ?;\", (df.loc[i][\"date\"],))\n",
    "            queryOut = c.fetchall()\n",
    "            \n",
    "            # Data does not already exist in the database \n",
    "            if len(queryOut) == 0: \n",
    "                df_not_dup_data = pd.concat([df_not_dup_data, df.loc[[i]]])\n",
    "            # Data already exists in the database with duplicate values\n",
    "            elif queryOut[0][1] == df.loc[i][\"value\"]: \n",
    "                df_dup_data = pd.concat([df_dup_data, df.loc[[i]]])\n",
    "            # Data already exists in the database but with different values\n",
    "            elif queryOut[0][1] != df.loc[i][\"value\"]:\n",
    "                df_inconsistent_data = pd.concat([df_inconsistent_data, df.loc[[i]]])            \n",
    "    else:\n",
    "        df_not_dup_data = df.copy()\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    df_not_dup_data = df_not_dup_data.sort_values(by=['date'])\n",
    "    \n",
    "    return df_not_dup_data, df_dup_data, df_inconsistent_data\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def get_max_index(tbl_name, db_name):\n",
    "    '''\n",
    "    Get the maximum index value of the specified tbl_name\n",
    "    '''\n",
    "    conn = create_connection(db_name)\n",
    "    c = conn.cursor()\n",
    "    try:\n",
    "        c.execute(\"SELECT MAX([index]) FROM \" + seriesID)\n",
    "        max_index = c.fetchone()[0]\n",
    "        return max_index\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "        \n",
    "def get_max_date(tbl_name, db_name):\n",
    "    '''\n",
    "    Get the maximum date from the specified tbl_name\n",
    "    '''\n",
    "    conn = create_connection(db_name)\n",
    "    c = conn.cursor()\n",
    "    try:\n",
    "        c.execute(\"SELECT date FROM \" + seriesID + \" WHERE [index] = (SELECT MAX([index]) FROM \" + seriesID +\")\")\n",
    "        max_date = c.fetchone()[0]\n",
    "        return max_date\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784b779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
